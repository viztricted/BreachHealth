{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to scrape data from the hhs breach portal https://ocrportal.hhs.gov/ocr/breach/breach_report.jsf and populate the Breach Healthcare website.  www.breachhealthcare.com.  \n",
    "\n",
    "The notebook uses the Selenium webdriver api to scrape data from the hhs portal.  The data is downloaded and then sent directly to a Google Sheet via the gspread api which is used as the source for a Tableau Public workbook.  Tableau Public enables a connection to Google Sheets enabling the workbooks to keep in sync with the Google Sheet.  \n",
    "\n",
    "There are a couple of areas I'm still working on developing including moving the csv file download location to a cloud environment, other than my PC.  The second area of improvement is having the python script kickoff automatically each day rather than manually running it.\n",
    "\n",
    "Before the automation, the process was fairly simple, but manual and time consuming.  The process was to go to the HHS portal site, download one csv file for Archived records, download another file for records Under Investigation, combine the two files and save.  Then open Tableau, refresh the existing tables and republish the scorecard.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202011060909\n",
      "202011060910\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "#this code is for the Selenim web driver to get files\n",
    "browser = webdriver.Chrome('C:/chromedriver_win32/chromedriver.exe')\n",
    "url = 'https://ocrportal.hhs.gov/ocr/breach/breach_report.jsf'\n",
    "browser.get(url) \n",
    "\n",
    "#This code downloads UI csv - the xpath was created by viewing the page source on the url to find the button pushed\n",
    "browser.find_element_by_xpath('//*[@id=\"ocrForm:j_idt365\"]').click()\n",
    "time.sleep(5)\n",
    "browser.close()\n",
    "\n",
    "today = pd.Timestamp.today().strftime('%Y%m%d%H%M')\n",
    "fileformat = '_UnderInvestigation_'\n",
    "print(today)\n",
    "\n",
    "#the Selenium web driver uses Chrome to download the file to my downloads folder\n",
    "fd = r\"C:\\Users\\ted\\Downloads\\breach_report.csv\"\n",
    "\n",
    "#To keep files organized, and maintaina history, the file is moved to a different folder and appended with the format and date\n",
    "os.rename(fd,r'C:\\Users\\ted\\OneDrive - Viztric\\Clients\\Shame Healthcare\\BreachReport'+fileformat+today+'.csv') \n",
    "\n",
    "#Finds the most recent file in list to create a dataframe from\n",
    "list_of_files = glob.glob(r'C:\\Users\\ted\\OneDrive - Viztric\\Clients\\Shame Healthcare\\*'+fileformat+'*') # * means all if need specific format then *.csv\n",
    "latest_file = max(list_of_files, key=os.path.getmtime)\n",
    "#print(list_of_files)\n",
    "#print(latest_file)\n",
    "\n",
    "#Creates a dataframe of Under Investigation records\n",
    "df_ui = pd.read_csv(latest_file, parse_dates=['Breach Submission Date'])\n",
    "#adds columns for Download data and FileType - the '_' is used to make a prettier file name, but stripped for the dataframe\n",
    "df_ui['DownloadDate'] = today\n",
    "df_ui['FileType'] = fileformat.strip('_')\n",
    "#print(df_ui.head())\n",
    "\n",
    "browser = webdriver.Chrome('C:/chromedriver_win32/chromedriver.exe')\n",
    "url = 'https://ocrportal.hhs.gov/ocr/breach/breach_report.jsf'\n",
    "browser.get(url) \n",
    "\n",
    "#This code selects the \"Archive\" then downloads csv\n",
    "browser.find_element_by_xpath('//*[@id=\"ocrForm:j_idt24\"]').click()\n",
    "time.sleep(5)\n",
    "browser.find_element_by_xpath('//*[@id=\"ocrForm:j_idt365\"]').click()\n",
    "time.sleep(15)\n",
    "browser.close()\n",
    "\n",
    "today = pd.Timestamp.today().strftime('%Y%m%d%H%M')\n",
    "fileformat = '_Archive_'\n",
    "print(today)\n",
    "\n",
    "#the Selenium web driver uses Chrome to download the file to my downloads folder\n",
    "fd = r\"C:\\Users\\ted\\Downloads\\breach_report.csv\"\n",
    "\n",
    "#To keep files organized, and maintaina history, the file is moved to a different folder and appended with the format and date\n",
    "os.rename(fd,r'C:\\Users\\ted\\OneDrive - Viztric\\Clients\\Shame Healthcare\\BreachReport'+fileformat+today+'.csv') \n",
    "\n",
    "\n",
    "fileformat = '_Archive_'\n",
    "list_of_files = glob.glob(r'C:\\Users\\ted\\OneDrive - Viztric\\Clients\\Shame Healthcare\\*'+fileformat+'*') # * means all if need specific format then *.csv\n",
    "latest_file = max(list_of_files, key=os.path.getmtime)\n",
    "#print(list_of_files)\n",
    "#print(latest_file)\n",
    "\n",
    "#Creates a dataframe of the Archived records\n",
    "df_arc = pd.read_csv(latest_file, parse_dates=['Breach Submission Date'])\n",
    "df_arc['DownloadDate'] = today\n",
    "df_arc['FileType'] = fileformat.strip('_')\n",
    "\n",
    "#print(df_arc.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This step combines the two dataframes together for one completed file for visualization\n",
    "df_comb= df_arc.append(df_ui)\n",
    "\n",
    "#Following are some check steps I used to see the sizes of each of the dataframes used\n",
    "#print(df_arc.shape)\n",
    "#print(df_ui.shape)\n",
    "#print(df_comb.shape)\n",
    "#print(df_comb.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This set of code writes the data to a google sheet which is the source file for a Tableau Public workbook\n",
    "\n",
    "import gspread\n",
    "from df2gspread import df2gspread as d2g\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "scope = [\n",
    "   'https://spreadsheets.google.com/feeds',\n",
    "         'https://www.googleapis.com/auth/drive']\n",
    "#Name of our Service Account Key\n",
    "google_key_file = r'C:\\Users\\ted\\PycharmProjects\\GoogleSheet\\black-works-294121-c065a334cd8d.json'\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name(google_key_file, scope)\n",
    "gc = gspread.authorize(credentials)\n",
    "\n",
    "spreadsheet_key = '1hrdiSg1CYvmI6-L38Z3B1H86zbFg0Kup8cdNguAjfL8'\n",
    "\n",
    "wks_name = 'Sheet1'\n",
    "#workbook = gc.open_by_key(spreadsheet_key)\n",
    "\n",
    "sheet = gc.open(\"BreachSheet\").sheet1\n",
    "\n",
    "\n",
    "#Deletes all of the code in the existing sheet and resizes to create \"fresh\" worksheet.\n",
    "sheet.clear()\n",
    "sheet.resize(rows=1, cols=1)\n",
    "\n",
    "\n",
    "#this last step sends the data to GoogleSheets\n",
    "set_with_dataframe(sheet, df_comb, include_column_header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
